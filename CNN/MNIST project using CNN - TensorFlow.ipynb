{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "989e0a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets\n",
    "from tensorflow.python import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "56c4790c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the data\n",
    "mnist = tensorflow_datasets.load('mnist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e298a717",
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables used\n",
    "# input details\n",
    "input_width = 28\n",
    "input_height = 28\n",
    "input_channels = 1\n",
    "input_pixels = 784\n",
    "\n",
    "# layer details - units, filter sizes, stride\n",
    "n_conv1 = 32\n",
    "n_conv2 = 64\n",
    "n_hidden = 1024\n",
    "n_out = 10\n",
    "\n",
    "conv1_k = conv2_k = 5\n",
    "max_pool1_k = max_pool2_k = 2\n",
    "\n",
    "stride_conv1 = stride_conv2 = 1\n",
    "\n",
    "input_size_to_hidden = (input_width//(max_pool1_k * max_pool2_k)) * (input_height//(max_pool1_k * max_pool2_k)) * n_conv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "57885fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing weights and biases\n",
    "weights = {\n",
    "    \"wc1\" : tf.Variable(tf.random.normal([conv1_k, conv1_k, input_channels, n_conv1])),\n",
    "    \"wc2\" : tf.Variable(tf.random.normal([conv2_k, conv2_k, n_conv1, n_conv2])),\n",
    "    \"wh1\" : tf.Variable(tf.random.normal([input_size_to_hidden, n_hidden])),\n",
    "    \"wo\" : tf.Variable(tf.random.normal([n_hidden, n_out]))\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    \"bc1\" : tf.Variable(tf.random.normal([n_conv1])),\n",
    "    \"bc2\" : tf.Variable(tf.random.normal([n_conv2])),\n",
    "    \"bh1\" : tf.Variable(tf.random.normal([n_hidden])),\n",
    "    \"bo\" : tf.Variable(tf.random.normal([n_out]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c8b7e93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convlution layer\n",
    "\"\"\"\n",
    "1. Apply filter to the image -> conv2d()\n",
    "conv2d(input, weights, biases, padding_type, strides = [no_of_examples, filter_width, filter_height, input_channel])\n",
    "All the times, no_of_examples and input_channel is set to 1.\n",
    "So, all the images will get processed 1 by 1 without skipping.\n",
    "input channel indicates filter_depth.\n",
    "\n",
    "2. Adding bias values -> bias_add()\n",
    "3. Applying relu activation function\n",
    "\"\"\"\n",
    "def conv(x, weights, biases, strides = 1):\n",
    "    out = tf.nn.conv2d(x, weights, padding = \"SAME\", strides = [1, strides, strides, 1])\n",
    "    out = tf.nn.bias_add(out, biases)\n",
    "    out = tf.nn.relu(out)\n",
    "    \n",
    "    return out\n",
    "\n",
    "# Max pooling layer\n",
    "\"\"\"\n",
    "Applying pooling to the image -> max_pool()\n",
    "max_pool(input, padding_type, ksize = [no_of_images, pooling_filter_width, pooling_filter_height, input_channel], strides = [no_of_examples, filter_width, filter_height, input_channel])\n",
    "ksize argument -> pooling_filter_size\n",
    "no_of_images and input_channel argument is always set to 1.\n",
    "So, that the filter cover fills up the entire space completely including the depth.\n",
    "\"\"\"\n",
    "def maxpooling(x, k = 2):\n",
    "    return tf.nn.max_pool(x, padding = \"SAME\", ksize = [1, k, k, 1], strides = [1, k, k, 1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "1b5d171d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward propogation\n",
    "\"\"\"\n",
    "1. Reshape the image from 784 pixels to 28*28*1 (1 -> input channel) 1D to 2D\n",
    "2. pass step 1 o/p through convolution layer 1 and max pooling 1\n",
    "3. pass step 2 o/p through convolution layer 2 and max pooling 2\n",
    "4. Reshape the step 3 o/p image from (7*7*64) to 3136 pixels (1 -> input channel) 2D to 1D and pass it through hidden layer with relu activation\n",
    "5. Pass step 4 o/p through output layer with identity activation function \n",
    "\"\"\"\n",
    "def cnn(x, weights, biases, keep_prob):\n",
    "    x = tf.reshape(x, [-1, input_width, input_height, input_channels])\n",
    "    \n",
    "    conv1 = conv(x, weights[\"wc1\"], biases[\"bc1\"], stride_conv1)\n",
    "    conv1_pool = maxpooling(conv1, max_pool1_k)\n",
    "    \n",
    "    conv2 = conv(conv1_pool, weights[\"wc2\"], biases[\"bc2\"], stride_conv2)\n",
    "    conv2_pool = maxpooling(conv2, max_pool2_k)\n",
    "    \n",
    "    hidden_input = tf.reshape(conv2_pool, shape = [-1, input_size_to_hidden])\n",
    "    hidden_output_before_activation = tf.add(tf.matmul(hidden_input, weights[\"wh1\"]), biases[\"bh1\"])\n",
    "    hidden_output_before_dropout = tf.nn.relu(hidden_output_before_activation)\n",
    "    hidden_output = tf.nn.dropout(hidden_output_before_dropout, keep_prob)\n",
    "    \n",
    "    output = tf.add(tf.matmul(hidden_output, weights[\"wo\"]), biases[\"bo\"])\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "4382027b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting into input and output\n",
    "x = tf.compat.v1.placeholder(\"float\", [None, input_pixels])\n",
    "y = tf.compat.v1.placeholder(tf.int32, [None, n_out])\n",
    "keep_prob = tf.compat.v1.placeholder(\"float\")\n",
    "                \n",
    "pred = cnn(x, weights, biases, keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "f48297f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cost function\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = pred, labels = y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "64cc1589",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "minimize() missing 1 required positional argument: 'var_list'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11976\\2290073663.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# optimization\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlearning_rate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.01\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0moptimize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcost\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: minimize() missing 1 required positional argument: 'var_list'"
     ]
    }
   ],
   "source": [
    "# optimization\n",
    "optimizer = tf.optimizers.Adam(learning_rate = 0.01)\n",
    "optimize = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "f010069c",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'Session'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11976\\2483231798.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msess\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'Session'"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.compat.v1.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b390c4f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
